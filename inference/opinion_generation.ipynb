{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f99805-8029-482a-88c4-65b0ee483d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import contextlib\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5625a6ca-a865-4e53-b6d2-e23cb3414484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dems_tokenizer = GPT2Tokenizer.from_pretrained('../models/gpt2_dems_full_data_single_follow/checkpoint-1230444/')\n",
    "# dem_model = GPT2LMHeadModel.from_pretrained('../models/gpt2_dems_full_data_single_follow/checkpoint-1230444/')\n",
    "\n",
    "# repub_tokenizer = GPT2Tokenizer.from_pretrained('../models/gpt2_repubs_full_data_single_follow/checkpoint-490180/')\n",
    "# repub_model = GPT2LMHeadModel.from_pretrained('../models/gpt2_repubs_full_data_single_follow/checkpoint-490180/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4d8b29e-2538-4bd6-9858-80134defdb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://huggingface.co/blog/how-to-generate\n",
    "\n",
    "def generate_with_a_prompt(prompt, text_gen_pipeline):\n",
    "    \"\"\"\n",
    "    Generate a list of statements given the prompt based on one GPT-2 model\n",
    "    \n",
    "    TODO:\n",
    "        - temperature\n",
    "    \n",
    "    NOTES:\n",
    "        1. 50256 corresponds to '<|endoftext|>'\n",
    "    \"\"\"\n",
    "    \n",
    "    results = text_gen_pipeline(prompt, \n",
    "                                max_length=30,\n",
    "                                temperature=0.5,\n",
    "                                num_return_sequences=100,\n",
    "                                pad_token_id=50256,\n",
    "                                clean_up_tokenization_spaces=True\n",
    "                               )\n",
    "    results = [res['generated_text'].split(\"\\n\")[0] for res in results]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb29958-ffdc-4209-a5b8-b19d153c7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem_generator = pipeline('text-generation', model='../models/gpt2_dems_full_data_single_follow/', device=0)\n",
    "dem_generator = pipeline('text-generation', model='../models/pretrained_gpt2_dems_4M_full_data_single_follow/', device=0)\n",
    "\n",
    "repub_generator = pipeline('text-generation', model='../models/gpt2_reps_full_data/', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a14a31f-406b-42e6-b72f-2f59a002b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a0cf94b6f4fb1aa522e1e218e60cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a991fcfd83f445d8820f7e292ec1e2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d07683669e46b9b662e1445776a6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29003a1c8b14ada83bb2fd13071e0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89968327fbd4766affd9f1e2e0f88eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\",\n",
    "                           model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "                           tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5191b2ed-7a43-4371-b0bc-0d8bda7f6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_opinion(prompt, text_gen, SentimentModel):\n",
    "#     Sentiment2score = {\n",
    "#         \"Positive\": 1,\n",
    "#         \"Neutral\": 0,\n",
    "#         \"Negative\": -1\n",
    "#     }\n",
    "    \n",
    "    Sentiment2score = {\n",
    "    \"Negative\": 0,\n",
    "    \"Positive\": 100,\n",
    "    \"Neutral\": 50\n",
    "    }\n",
    "    \n",
    "    results = generate_with_a_prompt(prompt, text_gen)\n",
    "    preds = SentimentModel(results)\n",
    "    scores = [Sentiment2score[pred['label']] for pred in preds]\n",
    "    \n",
    "    return np.array(scores).mean(), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "428ead7b-431d-429e-bbbe-122caa431687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Democrat</th>\n",
       "      <th>Republican</th>\n",
       "      <th>is_repub_leading</th>\n",
       "      <th>Prompt1</th>\n",
       "      <th>Prompt2</th>\n",
       "      <th>Prompt3</th>\n",
       "      <th>Prompt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fttrump1</td>\n",
       "      <td>17.664378</td>\n",
       "      <td>77.833163</td>\n",
       "      <td>True</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Donald Trump is</td>\n",
       "      <td>Donald Trump is a</td>\n",
       "      <td>Donald Trump is the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftobama1</td>\n",
       "      <td>81.292704</td>\n",
       "      <td>29.992821</td>\n",
       "      <td>False</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Barack Obama is</td>\n",
       "      <td>Barack Obama is a</td>\n",
       "      <td>Barack Obama is the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftbiden1</td>\n",
       "      <td>66.497423</td>\n",
       "      <td>24.401235</td>\n",
       "      <td>False</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Joe Biden is</td>\n",
       "      <td>Joe Biden is a</td>\n",
       "      <td>Joe Biden is the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftwarren1</td>\n",
       "      <td>59.843478</td>\n",
       "      <td>20.457680</td>\n",
       "      <td>False</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Elizabeth Warren is</td>\n",
       "      <td>Elizabeth Warren is a</td>\n",
       "      <td>Elizabeth Warren is the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0   Democrat  Republican  is_repub_leading           Prompt1  \\\n",
       "0   fttrump1  17.664378   77.833163              True      Donald Trump   \n",
       "1   ftobama1  81.292704   29.992821             False      Barack Obama   \n",
       "2   ftbiden1  66.497423   24.401235             False         Joe Biden   \n",
       "3  ftwarren1  59.843478   20.457680             False  Elizabeth Warren   \n",
       "\n",
       "               Prompt2                Prompt3                  Prompt4  \n",
       "0      Donald Trump is      Donald Trump is a      Donald Trump is the  \n",
       "1      Barack Obama is      Barack Obama is a      Barack Obama is the  \n",
       "2         Joe Biden is         Joe Biden is a         Joe Biden is the  \n",
       "3  Elizabeth Warren is  Elizabeth Warren is a  Elizabeth Warren is the  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./anes2020_pilot_prompt_probing.csv\")\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3016e965-5323-4fdc-b1ed-6f726efea4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjian42/.conda/envs/change/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "Barack Obama is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Joe Biden is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Elizabeth Warren is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Bernie Sanders is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Pete Buttigieg is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Kamala Harris is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Amy Klobuchar is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Mike Pence is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "Andrew Yang is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Nancy Pelosi is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Marco Rubio is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "Alexandria Ocasio-Cortez is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Nikki Haley is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "Clarence Thomas is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "Dr. Anthony Fauci is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "black people are the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "white people are the\n",
      "Gold Label: 1\n",
      "Pred Label: 0\n",
      "\n",
      "Hispanic people are the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "Asian people are the\n",
      "Gold Label: 0\n",
      "Pred Label: 1\n",
      "\n",
      "illegal immigrants are the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "feminists are the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "the #MeToo movement is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "transgender people are the\n",
      "Gold Label: 0\n",
      "Pred Label: 1\n",
      "\n",
      "socialists are the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "capitalists are the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "big business is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "labor unions is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n",
      "the Republican Party is the\n",
      "Gold Label: 1\n",
      "Pred Label: 1\n",
      "\n",
      "the Democratic Party is the\n",
      "Gold Label: 0\n",
      "Pred Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../data/prompts/partisan_prefix_prompts.txt\", header=None)\n",
    "\n",
    "pred_labels = []\n",
    "pred_avg_sentiments = []\n",
    "gold_labels = []\n",
    "prompts = []\n",
    "prompts\n",
    "for prompt, gold_label in df[[\"Prompt4\", 'is_repub_leading']].values:\n",
    "    prompt = prompt.strip()\n",
    "    gold_label = int(gold_label)\n",
    "    # gold_label = {\"positive\": 1, \"negative\": 0}[gold_label]\n",
    "    \n",
    "    avg_dem_sentiment, _ = aggregate_opinion(prompt, dem_generator, sentiment_model)\n",
    "    avg_repub_sentiment, _ = aggregate_opinion(prompt, repub_generator, sentiment_model)\n",
    "    \n",
    "    pred_avg_sentiments.append((avg_repub_sentiment, avg_dem_sentiment))\n",
    "    if avg_repub_sentiment > avg_dem_sentiment:\n",
    "        pred_label = 1\n",
    "    else:\n",
    "        pred_label = 0\n",
    "        \n",
    "    pred_labels.append(pred_label)\n",
    "    gold_labels.append(gold_label)\n",
    "    prompts.append(prompt)\n",
    "    print(prompt)\n",
    "    print(\"Gold Label:\", gold_label)\n",
    "    print(\"Pred Label:\", pred_label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab76b003-ea17-429c-80f8-bd0c02e3cbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(gold_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f5ce366-fc6d-487f-855b-5560d6ba2797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(80.5, 6.5),\n",
       " (5.0, 69.5),\n",
       " (10.5, 78.5),\n",
       " (56.5, 85.0),\n",
       " (62.0, 79.0),\n",
       " (43.5, 81.0),\n",
       " (18.0, 88.5),\n",
       " (26.5, 53.5),\n",
       " (50.5, 11.5),\n",
       " (48.0, 73.0),\n",
       " (1.0, 44.0),\n",
       " (53.0, 18.5),\n",
       " (34.0, 57.5),\n",
       " (51.5, 34.0),\n",
       " (71.0, 56.0),\n",
       " (45.5, 73.0),\n",
       " (4.0, 10.0),\n",
       " (2.5, 5.5),\n",
       " (9.5, 16.0),\n",
       " (9.0, 7.0),\n",
       " (0.5, 2.5),\n",
       " (2.5, 9.5),\n",
       " (29.5, 64.5),\n",
       " (15.5, 15.0),\n",
       " (2.5, 5.5),\n",
       " (5.5, 2.0),\n",
       " (33.0, 31.5),\n",
       " (37.5, 52.0),\n",
       " (5.0, 0.5),\n",
       " (0.0, 19.5)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_avg_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edeec33e-58fa-409b-871b-8a012ee9d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjian42/.conda/envs/change/lib/python3.8/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sentiment, results = aggregate_opinion(\"Fauci is\", dem_generator, sentiment_model)\n",
    "avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7c4a24f-3d04-4a16-aa3d-e1410b063827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sentiment, _ = aggregate_opinion(\"Fauci is\", repub_generator, sentiment_model)\n",
    "avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a59a798-c0b4-4ad7-a63c-ad2c612ddde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0baec156-f1df-4c5c-bac9-6b74471f0759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.8878867030143738},\n",
       " {'label': 'Negative', 'score': 0.8414068222045898},\n",
       " {'label': 'Negative', 'score': 0.9111444354057312},\n",
       " {'label': 'Negative', 'score': 0.9114534854888916},\n",
       " {'label': 'Negative', 'score': 0.9371337890625},\n",
       " {'label': 'Negative', 'score': 0.8892924189567566},\n",
       " {'label': 'Negative', 'score': 0.8128095865249634},\n",
       " {'label': 'Negative', 'score': 0.8801783323287964},\n",
       " {'label': 'Negative', 'score': 0.9490361213684082},\n",
       " {'label': 'Negative', 'score': 0.9414410591125488}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6b536-2020-48ca-8f77-a4be05d90313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
